var tipuesearch = {"pages":[{"title":"Introducing myself","text":"My name is Gabriel Weindel and I am a cognitive scientist currently working at Aix-Marseille Université (France) in the Laboratoire de Psychologie Cognitive and Laboratoire de Neurosciences Cognitives. I am specialized in, and fond of, mental chronometry. This field of cognitive sciences, as I define it, addresses the question of the timing of information processing operated by the cognitive system implemented by our brains. As a researcher my interest goes to the test and application of mathematical cognitive models to the general population or to populations with cognitive deficits. For a detailed summary of my curriculm see my CV","tags":"pages","url":"/introducing-myself","loc":"/introducing-myself"},{"title":"A surprising link between electrophysiological data in monkeys and a behavioral model in humans","text":"A surprising link between electrophysiological data in monkeys and a behavioral model in humans Preamble With Thibault Gajdos, Boris Burle and F.-Xavier Alario we recently published a preprint titled \"The Decisive Role of Non-Decision Time for Interpreting the Parameters of Decision Making Models\". As in any article, some choices had to be made and what I am presenting in this post was not the focus of the article (plus the analysis was unplanned and therefore should be taken with a grain of salt), but I still wanted to share this result as I find it extremely interesting. In the study reported in the preprint, using experimental manipulations and an electrophysiological measure of response execution, we evaluated the ability of a decision-making model to account for latent cognitive processes in a perceptual decision task. In this task we manipulated the amount of force to produce a response, speed accuracy trade-off instructions and finally stimulus contrast. This last manipulation had an interesting property that revealed a surprising pattern ! But let's first review the task of the participants and some of the results from the study. The task Participants had to indicate which of two sinusoidal gratings, left and right of a fixation cross, had the most contrast in it with the corresponding button press (hint : it's on the left on the next image): Now the contrast manipulation consisted in increasing the overall contrast of both stimuli while maintaining their difference constant : Higher contrast, as on the right of the previous image, yields faster brain response even in the earliest visual sensory systems compared to dimmer stimuli. The nice thing about that manipulation is that, according to the law of Weber-Fechner, the difficulty in comparing the gratings increases with the increase in brightness. This can be seen on the behavioral performance, participants proportion of errors and Reaction Times ($RT$) increase when contrast increases (see the preprint for details of the figure) : Hence we have here a manipulation where you expect that the time for visual encoding of the stimulus evolves inversly to the time you need to decide. The overall measure of RT cannot show you both effects as they are weighting each other out. Ideally we would like to have a cognitive model of behavior accounting for both dimensions of decision and encoding times but that seems like a hard test for a model. In our paper we tested amongst others, whether the well-known Drift Diffusion Model (as implemented by Ratcliff, \\& Tuerlinckx, 2002) captures simultaneously the decision and visual encoding properties of this manipulation. Initial results The increase in decision time is obviously captured by the model given the high impact of the increase in contrast on both participants accuracy and $RT$s. More interesting is the fact that the model is also able to capture the decrease in the parameter assumed to relate to visual encoding of the stimulus with the increase in contrast. Let's illustrate it with the actual data from the preprint : In [1]: # I provide the code for each figure just for those who could be interested but you can skip these cells and just look at the outputs # Following loads the packages and the data from the github of the preprint import matplotlib.pyplot as plt import numpy as np import pandas as pd import arviz as az plt . style . use ( 'seaborn-ticks' ) #Plotting theme PMTstats = pd . read_csv ( 'https://github.com/GWeindel/The-Decisive-Role-of-Non-Decision-Time/raw/main/DDM/PMT_M13_stats.csv' , index_col = 0 ) ## Recovering DDM estimates from fit PMTtraces = pd . read_csv ( 'https://github.com/GWeindel/The-Decisive-Role-of-Non-Decision-Time/raw/main/DDM/PMT_M13_traces.csv' , index_col = 0 ) ## See the preprint for the details The following figure illustrates this observation, the parameter for encoding time ($T_{e}$ y-axis) is indeed decreasing with contrast increase (x-axis). In [2]: plt . figure ( figsize = ( 5 , 4 ), dpi = 150 ) #Graphical parameters m = PMTstats [ PMTstats . index . str . contains ( \"t\\(low.Speed\" )][ \"mean\" ] #Taking a subset (the best) of the estimates from the preprints # Plotting these points plt . errorbar ( np . linspace ( 23 , 93 , 6 ), m * 1000 , ls = '' , marker = \"o\" , c = \"indianred\" ) # Other graphical parameters plt . ylabel ( r '$T_ {e} $ Encoding Time parameter (ms)' ) plt . xlabel ( 'Contrast (%)' ); Great news , a model like the drift diffusion model, using only RTs and choices, is able to show that visual encoding time is decreasing even though difficulty is increasing the $RT$s (although that is only true under some conditions and there is some uncertainty associated but see the preprint). A surprising link Now one thing is particularly interesting. I started to talk with scientists with more expertise in visual processing about the experiment. At that occasion I was redirected to an article written in 2012 by Reynaud, Masson and Chavane ( https://doi.org/10.1523/JNEUROSCI.1618-12.2012 ). In their article the authors analyze, using voltage-sensitive dye, the temporal dynamics of visual neuron in the primary visual cortex, V1, of two monkeys ( Macaca mulata ) in response to a visual grating similar to the one we used. In one of their analysis (see Figure 5B. of their article) they report measurement of onset of activity in V1 neurons in response to different contrasts of the grating. Using the Naka-Rushton equation, a well known luminance-response function, in its inverted version (Barthelemy, Fleuriet \\& Masson, 2010) they provide a description of the onset of activity in V1 in response to different contrast levels. Now things are getting even more interesting. One test we could do is : does the data from these monkeys relate to our estimate of visual encoding time in human using only a behavioral model (and some physiological information about response execution) ? That would be wild but we tested it anyway, especially because the lead author of the paper on V1 activity in monkeys guessed that we should have a non-linear relationship which is indeed apparent in the previous Figure. The only thing we had to do was to recover the parameters of the inverted Naka-Rushton they obtained and generate predictions for the contrast levels we used in our study. Then we can just compare their predictions and our estimate of visual encoding in humans. In [3]: def Naka_Rushton ( par , contrast , maxAmp , maxShift ): #Inverted Naka-rushton equation from Barthélemy, Fleuriet and Masson 2010 c50 , slope = par [ 0 ], par [ 1 ] return ( maxAmp + maxShift * (( contrast ** slope ) / (( c50 ** slope ) + ( contrast ** slope )))) # Hereby we obtain the prediction of onset of neurons in V1, for the contrast level we used, with the parameters we recovered from their article # To see how we recovered the parameters see https://github.com/GWeindel/The-Decisive-Role-of-Non-Decision-Time/blob/main/3-DDM_analysis.ipynb predicted_V1 = Naka_Rushton ( par = [ 11.42 , - 1.54 ] , maxAmp = 36.99 , maxShift = 51.66 , contrast = np . linspace ( 23 , 93 , 100 )) plt . figure ( figsize = ( 5 , 4 ), dpi = 150 ) plt . plot ( np . linspace ( 23 , 93.1 , 100 ), predicted_V1 , color = \"green\" ) #Plotting predictions plt . xlabel ( 'Contrast levels (%)' ) plt . ylabel ( 'V1 predicted neuron response time (ms)' ); Damned that looks close !! What if we superpose both ? Well we could do that simply by displaying both, but obviously V1 neurons respond really fast and visual processing goes on beyond the first response latency, therefore we need to be on the same scale. We did this be simply subtracting the mean of each variable (human behavioral model vs V1 measurment) to each data point from the same variable ($x_i - \\overline{x}$). Doing so we only keep the relative difference of each contrast point to the mean of each variable. In [4]: plt . figure ( figsize = ( 5 , 4 ), dpi = 150 ) # plotting the centered predictions plt . plot ( np . linspace ( 23 , 93 , 100 ), predicted_V1 - np . mean ( predicted_V1 ), color = \"green\" , label = r 'V1 predictions' ) # Recovering the estimates of the behavioral model for humans m = PMTstats [ PMTstats . index . str . contains ( \"t\\(low.Speed\" )][ \"mean\" ] # I only use mean, see preprint for full uncertainty representation m_scaled = m - np . mean ( m ) # centering # plotting the centered estimates plt . errorbar ( np . linspace ( 23 , 93 , 6 ), m_scaled * 1000 , #*1000 to convert to milliseconds ls = '' , marker = \"o\" , c = \"indianred\" , label = '$T_ {e} $ estimates' ) # Paramètres graphiques plt . legend ( frameon = True ) plt . ylabel ( r 'Centered Time (ms)' ) plt . xlabel ( 'Contrast' ); Wow... That is impressive ! A behavioral model (+ physiology of response execution) fitted on data from a decision making task performed by humans is capturing visual encoding latencies that very closely match actual measurment of primary visual neurons in monkeys ! It is important to note that no fit occurred between V1 predictions and the estimated encoding time, we just centered each variable ! Now the story doesn't end here This congruence for example only happens when we particularly stress participants to respond as fast as possible. When we switch to an accuracy-focused condition, things do really not look the same : In [5]: plt . figure ( figsize = ( 5 , 4 ), dpi = 150 ) # plotting the centered predictions plt . plot ( np . linspace ( 23 , 93 , 100 ), predicted_V1 - np . mean ( predicted_V1 ), color = \"green\" , label = r 'V1 predictions' ) # Recovering the estimates of the behavioral model for humans m = PMTstats [ PMTstats . index . str . contains ( \"t\\(low.Accuracy\" )][ \"mean\" ] # I only use mean, see preprint for full uncertainty representation m_scaled = m - np . mean ( m ) # centering # plotting the centered estimates plt . errorbar ( np . linspace ( 23 , 93 , 6 ), m_scaled * 1000 , #*1000 to convert to milliseconds ls = '' , marker = \"o\" , c = \"indianred\" , label = '$T_ {e} $ estimates' ) # Paramètres graphiques plt . legend ( frameon = True ) plt . ylabel ( r 'Centered Time (ms)' ) plt . xlabel ( 'Contrast' ); But still, the fact that physiological measurment of primary visual cortex neurons from another specie predicts that well the estimates of a behavioral model of decision making in humans is a really impressive performance ! Bibliography Barthélemy, F. V., Fleuriet, J., & Masson, G. S. (2010). Temporal dynamics of 2D motion integration for ocular following in macaque monkeys. Journal of neurophysiology, 103(3), 1275-1282. Ratcliff, R., & Tuerlinckx, F. (2002). Estimating parameters of the diffusion model: Approaches to dealing with contaminant reaction times and parameter variability. Psychonomic bulletin & review, 9(3), 438-481. Reynaud, A., Masson, G. S., & Chavane, F. (2012). Dynamics of local input normalization result from balanced short-and long-range intracortical interactions in area V1. Journal of neuroscience, 32(36), 12558-12569.","tags":"posts","url":"/a-surprising-link-between-electrophysiological-data-in-monkeys-and-a-behavioral-model-in-humans","loc":"/a-surprising-link-between-electrophysiological-data-in-monkeys-and-a-behavioral-model-in-humans"},{"title":"RunDMC in a jupyter notebook","text":"Sorry, it's not about how to invite runDMC rappers to feature your notebook, rather it is about using the package \"dynamic models of choice\" ( runDMC ), to fit decision making models to your behavioral (and physiological) data within the environment of Jupyter. Why you ask ? Well, I'm allergic to development environment such as Rstudio or Rmarkdown as they are, to me, not practical enough when it comes to explore your data or your analysis pipeline while keeping a record of everything. For that I prefer the jupyter environment but installing R and it's packages can be tricky, especially with complex architectures such as the one required by runDMC. Therefore I wrote this short tutorial in case others want to use the ability of jupyter but still rely on runDMC to do your decision data anaysis. Setup We we'll be using conda, if you do not arleady have anaconda installed download the latest version at anaconda.com . First we will ensure that packages from conda are downloaded from the conda-forge repositories that has a larger collection of packages than default conda repositories. For that, in a terminal (for linux and Mac users) or using the anaconda prompt (for windows) launch the following command : conda config --add channels conda-forge conda config --set channel_priority strict Then we will simultaneously create a new environment called \"DMC\" with the available and required packages from conda-forge : conda create -n DMC r-loo r-hypergeo r-statmod r-pracma r-snowfall r-numDeriv r-vioplot r-ggplot2 r-gridExtra r-truncdist r-msm r-rlecuyer r-laplacesdemon r-mvtnorm r-matrix jupyter #That will take a while However a few of the required packages are not contained in the conda forge rep (rtdists, stringr, Brobdingnag) . We therefore have to launch an R session in the DMC environment to install them afterwards. For that first launch an R session by previously activating our new conda env : conda activate DMC R install.packages(\"Brobdingnag\") # This will prompt a screen requiring to select a server from which you will download, just select the nearest one install.packages(\"stringr\") install.packages(\"rtdists\") Then we will install a modified version of the coda package that allows for plotting of priors with plot.dmc. For that download the zip file from the latest DMC version , extract it in a relevant path and then move to that working directory within the R session, in my case and for the version 190819 it goes as follows : setwd(\"~/DMC_190819\") And install the coda package : install.packages(\"packages/coda_0.19-3.tar.gz\",repos=NULL,type=\"source\") Then R and jupyter packages are not interfacing very well you need a last step to provide jupyter with the relevant locations for the R packages : install.packages('IRkernel') IRkernel::installspec() Et voilà ! You're ready to go and use runDMC and the associated tutorials :) Let me know in case you run into troubles. See below (or download it here ) for an example of the notebook taken from DMC tutorial dmc_1_5_ddm.R : Demo : DMC Lesson 1 Models and Data Note: Before running these scripts, the current working directory must be set to the top-level folder containing the dmc and tutorial subfolders Lesson 1.5 Exploring the DDM model This lesson is about familiarising yourself with the DDM model and its parameters, and how you can create different scenarios with different parameter values. See Ratcliff, R., & McKoon, G. (2008). The diffusion decision model: Theory and data for two-choice decision tasks. Neural Computation, 20(4), 873–922. In [ ]: rm ( list = ls ()); par ( mfrow = c ( 1 , 1 )) source ( \"dmc/dmc.R\" ) load_model ( \"DDM\" , \"ddm.R\" ) Start with a simple design with a binary stimulus factor, S (e.g, left vs. right motion) and corresponding responses In [2]: factors = list ( S = c ( \"left\" , \"right\" )) responses = c ( \"LEFT\" , \"RIGHT\" ) match.map = list ( M = list ( left = \"LEFT\" , right = \"RIGHT\" )) NB1: See ?ddiffusion for rtdists help on parameters. However note that we differ from rtdists in defining z (the start point) relative to a (the boundary). That is, if the absolute start point is Z then z = Z/a, where 0 < z < 1. Similarly, sz, start point noise (i.e., the width of the uniform distribution around z of start points) is defined as a proportion of a, so if SZ is the absolute start point distribution width then sz = SZ/a. Note also that t0 is the LOWER BOUND of the non-decision time distribution (in this case this is true in both rtdists and in DMC) so, that mean non-decision time is t0 + st/2, where st is the width of the uniform distribution of non-decision time. These parameterization of z, sz and t0 are all adopted so that the parameters can be restricted to their proper range by priors bounded by absolute values (i.e, 0 < z < 1, 0 < sz < 1, t0 > 0 and st > 0) rather than having to provide relative bounds (e.g., Z < a etc.) NB2: Like the LNR, for the DDM there is no need to fix a parameter (by default moment-to-moment variability s=1 is assumed, see rtdists). Constants are set here just to focus on the computationally faster version with no non-decision variability (st0=0) and with no difference in non-decision time between responses (d=0). When st0>0 it gets slow! NB3: Because there is only one accumulator the M and R factors cannot appear in p.map NB4: Negative v is mapped to the error boundary and positive to correct boundary, so estimates are generally positive. NB5: Note that the left response corresponds to the bottom boundary (at 0) and the right response to the top boundary (at a) NB6: The underlying code calculating the DDM likelihood uses numerical integration in C and can crash when given parameters outside and even sometimes very near the boundaries over which each parameter is defined. In order to avoid these problems parameters are checked as follows and a zero likelihood returned (see transfrom.dmc in ddm.R) bad <- function(p) { (p$a[1]<0) | (p$z[1] <1e-6) | (p$z[1] >.999999) | (p$t0[1]<1e-6) | (p$sz[1]<0) | (p$st0[1]<0) | (p$sv[1]<0) | (p$sz[1]>1.999999*min(c(p$z[1],1-p$z[1]))) } Note that sz has a rather complicated from becasue we have to make sure that both 0 < Z - SZ/2 and Z + SZ/2 < a. This is the same as 0 < z-sz/2 and z+sz/2 < 1 or jointly sz/2 < min(z,1-z). NB7: The d parameter (difference in t0 between responses, positive values = faster for upper threshold, negative = faster for lower threshold) from rtdists is re-defined in a relative sense i.e., d_rtdists = t0 * d_dmc so it is easy to make sure that non-decison time for both responses is always positive by bounding -2 < d_dmc < 2. Simple no factor effects model In [3]: model <- model.dmc ( constants = c ( st0 = 0 , d = 0 ), type = \"rd\" , p.map = list ( a = \"1\" , v = \"1\" , z = \"1\" , d = \"1\" , sz = \"1\" , sv = \"1\" , t0 = \"1\" , st0 = \"1\" ), match.map = list ( M = list ( left = \"LEFT\" , right = \"RIGHT\" )), factors = list ( S = c ( \"left\" , \"right\" )), responses = c ( \"LEFT\" , \"RIGHT\" )) Parameter vector names are: ( see attr(,\"p.vector\") ) [1] \"a\" \"v\" \"z\" \"sz\" \"sv\" \"t0\" Constants are (see attr(,\"constants\") ): st0 d 0 0 Model type = rd 1) In this example accuracy is a bit above 75% In [4]: p.vector <- c ( a = 2 , v = 1 , z = 0.5 , sv = 1 , sz = 0.2 , t0 = . 2 ) data.model <- data.model.dmc ( simulate.dmc ( p.vector , model , n = 1e4 ), model ) plot.score.dmc ( data.model ) [1] 0.77 FALSE TRUE 1.07 0.88 Decreasing the threshold (a) decreases accuracy but increases speed In [5]: p.vector <- c ( a = 1 , v = 1 , z = 0.5 , sv = 1 , sz = 0.2 , t0 = . 2 ) data.model <- data.model.dmc ( simulate.dmc ( p.vector , model , n = 1e4 ), model ) plot.score.dmc ( data.model ) [1] 0.69 FALSE TRUE 0.43 0.41 3) Increasing start-point noise (sz) also decreases accuracy and increases speed (NOTE: sz must always be < a/2, otherwise an error occurs) In [6]: p.vector <- c ( a = 2 , v = 1 , z = 0.5 , sv = 1 , sz = . 9 , t0 = . 2 ) data.model <- data.model.dmc ( simulate.dmc ( p.vector , model , n = 1e4 ), model ) plot.score.dmc ( data.model ) [1] 0.72 FALSE TRUE 0.75 0.76 4) Decreasing v decreases accuracy and speed (mainly for correct responses in this case) In [7]: p.vector <- c ( a = 2 , v = 0.5 , z = 0.5 , sv = 1 , sz = 0.2 , t0 = . 2 ) data.model <- data.model.dmc ( simulate.dmc ( p.vector , model , n = 1e4 ), model ) plot.score.dmc ( data.model ) [1] 0.65 FALSE TRUE 1.06 0.95 5) Increasing sv mainly decreases accuracy (also a little RT) In [8]: p.vector <- c ( a = 2 , v = 1 , z = 0.5 , sv = 1.5 , sz = 0.2 , t0 = . 2 ) data.model <- data.model.dmc ( simulate.dmc ( p.vector , model , n = 1e4 ), model ) plot.score.dmc ( data.model ) [1] 0.71 FALSE TRUE 0.98 0.80 6) Increasing t0 decreases speed but has no effect on accuracy In [9]: p.vector <- c ( a = 2 , v = 1 , z = 0.5 , sv = 1 , sz = 0.2 , t0 = . 4 ) data.model <- data.model.dmc ( simulate.dmc ( p.vector , model , n = 1e4 ), model ) plot.score.dmc ( data.model ) [1] 0.77 FALSE TRUE 1.27 1.07 Now lets look at the effects of non-decision noise, so st0 is no longer a constant. Just as in LBA t0 is the lower bound of non-decision time and t0+st0 is the upper bound (so mean non-decision time is t0 + st0/2). In [10]: model <- model.dmc ( constants = c ( d = 0 ), type = \"rd\" , p.map = list ( a = \"1\" , v = \"1\" , z = \"1\" , d = \"1\" , sz = \"1\" , sv = \"1\" , t0 = \"1\" , st0 = \"S\" ), match.map = list ( M = list ( left = \"LEFT\" , right = \"RIGHT\" )), factors = list ( S = c ( \"left\" , \"right\" )), responses = c ( \"LEFT\" , \"RIGHT\" )) Parameter vector names are: ( see attr(,\"p.vector\") ) [1] \"a\" \"v\" \"z\" \"sz\" \"sv\" \"t0\" [7] \"st0.left\" \"st0.right\" Constants are (see attr(,\"constants\") ): d 0 Model type = rd Accuracy is unaffected by variability increases. In [11]: p.vector <- c ( a = 2 , v = 1 , z = 0.5 , sv = 1 , sz = 0.2 , t0 = 0.1 , st0.left = 0 , st0.right = 1 ) data.model <- data.model.dmc ( simulate.dmc ( p.vector , model , n = 1e4 ), model ) Score & plot In [12]: correct <- data.model $ S == tolower ( data.model $ R ) No effect on accuracy In [13]: round ( tapply ( correct , data.model $ S , mean ), 2 ) left 0.77 right 0.77 Mean RT is increased by st0/2 In [14]: round ( tapply ( data.model $ RT , data.model $ S , mean ), 2 ) left 0.83 right 1.31 Variability for left stimuli less than for right In [15]: round ( tapply ( data.model $ RT , data.model $ S , IQR ), 2 ) par ( mfrow = c ( 1 , 2 )) plot.cell.density ( data.model [ data.model $ S == \"left\" ,], C = correct [ data.model $ S == \"left\" ], xlim = c ( 0 , 5 ), main = \"left\" ) plot.cell.density ( data.model [ data.model $ S == \"right\" ,], C = correct [ data.model $ S == \"right\" ], xlim = c ( 0 , 5 ), main = \"right\" ) left 0.62 right 0.72","tags":"posts","url":"/rundmc-in-a-jupyter-notebook","loc":"/rundmc-in-a-jupyter-notebook"},{"title":"Lecture on Linear Mixed Models","text":"Introduction This is a series of lectures I gave to doctoral students in psychology and neuroscience at Aix-Marseille Université in April 2021. The course aimed at giving enough information and examples about mixed models to allow students to think about how they can apply such models to their data. All the course is intended to be \"hands-on\" and therefore the R code is provided with reproducible examples (mainly simulations). The code is meant to be accessible to beginners so it remains simple and redundant (and... I'm a python user so I don't get all the tidyverse things for now). All the content of the slides can be recreated as an interactive jupyter notebook where you can easily live code inside the presentation thanks to the RISE python package. If you're interested in replicating this lecture take a look at the root repository (https://github.com/GWeindel/lecture_mixed_models_AMU_2021) with all the instructions. Content of the course : Module 1 The first module is dedicated to linear models both as a reminder and to extend students knowledge on what can be done using linear models (prediction, factor recoding, etc.) The presentation can be found here (best to open in a separate tab and to navigate across slides with the space bar) Module 2 The second module introduces the core aspect of linear mixed models in a frequentist context and using the '''lme4''' R package. We start by illustrating the concept of maximum likelihood, hierarchies in the data and how to account for these hierarchies. The presentation can be found here Module 3 The last module introduces Bayesian estimation and generalized linear mixed models. The aim is to give students clues to understand these models fitted in a Bayesian context rather than being exhaustive, I conclude with a series of resources for those who want to go further in the learning of regression models and Bayesian estimation. The presentation can be found here","tags":"posts","url":"/lecture-on-linear-mixed-models","loc":"/lecture-on-linear-mixed-models"},{"title":"PhD","text":"Hi everyone, I had my PhD defense last month and I'm happy to share with you the manuscript that can be found on thesis commons . Along with the manuscript there is also an associated OSF project page where you can find most of the code used for the analysis in the PhD manuscript, some data is still missing but will be uploaded when the chapters get published. There is also a live recording of the presentation available : Cheers !","tags":"posts","url":"/phd","loc":"/phd"}]};